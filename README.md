<p align="center">
  <img src="PosterSprogTeknologiVers1.jpg" alt="Poster SprogTeknologisk Konference, KU 2022. " title="Poster SprogTeknologisk Konference, KU 2022.">
</p>

<h3>Prototype:</h3>
Code for the project prototype can be found <a href="Prototype/README.md">here</a>.<br>

<h3>Project Tutorials:</h3>
Can be found in this folder.<br>
(See the followting list of tutorial files for this <i>Semantic Similarity Search project</i>).<br>
<br>
-  <a href="IntroSpaCy.ipynb">IntroSpaCy.ipynb</a><br>
(Short intro to the SpaCy library).<br>
<br>
- <a href="WordCloud.ipynb">WordCloud.ipynb</a><br>
(How you can make your own WordClouds).<br>
<br>
- <a href="Newsgroup Categories.ipynb">Newsgroup Categories.ipynb</a><br>
(Classification of (your) text into 4 newsgroups).<br>
<br>
- <a href="NLPJobClassifier.ipynb">NLPJobClassifier.ipynb</a><br>
(Classification of jobs into groups "IT" or "non-IT").<br>
Uses the datajobsposts.csv dataset<br>
(available elsewhere on Github/Kaggle).<br>
<br>
- <a href="BasicTextAnalytics.ipynb">BasicTextAnalytics.ipynb</a><br>
(Misc. Techniques for basic text analytics).<br>
<br>
- <a href="SyntacticSimiliarity.ipynb">SyntacticSimiliarity.ipynb</a><br>
(Code for syntactic similarity).<br>
Uses the abcnews-date-text.csv dataset<br>
(available elsewhere on Github/Kaggle).<br>
<br>
- <a href="SemanticRelationshipWordEmbedding.ipynb">SemanticRelationshipWordEmbedding.ipynb</a><br>
(WordEmbeddings. Classic queen, king, man, woman example)<br>
<br>
- <a href="SentenceTransformerColabExampleEN.ipynb">SentenceTransformerColabExampleEN.ipynb</a><br>
(Transformers and semantic similarity, english).<br>
<br>
- <a href="SentenceTransformerColabExampleDK.ipynb">SentenceTransformerColabExampleDK.ipynb</a><br>
(Transformers and semantic similarity, danish).<br>
<br>
-  <a href="Wine_Classification.ipynb">Wine_Classification.ipynb</a><br> 
(A classic classification problem). <br>
Included here as part of a tutorial on ML techniques.<br>
<br>
- <a href="MyFirstQuad.ipynb">MyFirstQuad.ipynb</a><br>
(A question answer transformer). <br>
Included here as part of a tutorial on ML techniques.<br>
<br>
<br>
Details:<br>
<br>
This folder contains a number of NLP files used in connection with the JobTrend Project (at Eaaa).<br>
<br>
In the program Jobtrend, we have a search function that looks for skills in JobAds
(Skills that a company hope an employee have). Available courses at Eaaa should then
be able to give employees these skills.<br>
<br>
Matching skills taught in courses and skills searched for in job ads is not trivial though.
As these skills might be described in a number of different ways.<br>
<br>
As a part of my investigation on how we should implement this semantic similarity search - a
number of techniques have been tried out. Where I have saved some of the files from this work
here in this folder.<br>
<br>
In case you wonder what a Wine.ipynb notebook is doing among these files, then, well, :) 
I needed to include a file with a classic classification problem 
in this folder in connection with a workshop/tutorial. And I have talked about the Titanic
problem too many times by now, and needed a similar, but different, case to talk about here.
The question answer transformer MyFirstQuad.ipynb is included as a simple example of this technique.<br>
<br>
More transformer based code will be added as the project JobTrend progresses.<br>
<br>
Simon Laub.<br>
Email: sila<br>
<br>
About JobTrend<br>
(In Danish):<br>
<br>
Med database og analyseværktøj tilbyder Jobtrend arbejdsmarkedsanalyser. <br>
Disse analyser skal afdække uddannelsers relevans i forhold til det 
danske arbejdsmarked og på den måde understøtte udviklingen af uddannelser.<br>
<br>
På sigt kan der omvendt opstå øget ledighed på det danske arbejdsmarked, 
og i den situation er det vigtigt at bibringe dimittender og ledige kompetencer, 
som gør den attraktive på det danske arbejdsmarked. I samfundet er der samlet set et vedvarende
behov for at uddanne arbejdsstyrken til de kompetencer, som er aktuelt nu og i fremtiden, der er behov for på arbejdsmarkedet.


